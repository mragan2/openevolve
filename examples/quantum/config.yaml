# Configuration for semiclassical cosmology / quantum correction evolution

# ------------ General settings ------------
max_iterations: 150
checkpoint_interval: 25
log_level: "INFO"
random_seed: 42
file_suffix: ".py"          # default, but explicit is fine
diff_based_evolution: false # allow full rewrites instead of diffs
max_code_length: 10000

# ------------ LLM configuration ------------
llm:
  # Shared API configuration for all models
  api_base: "http://localhost:11434/v1"
  api_key: "YOUR_KEY_OR_DUMMY"   # Ollama ignores this, but field must exist or be omitted
  temperature: 0.9
  top_p: 0.98
  max_tokens: 4096
  timeout: 600
  retries: 3
  retry_delay: 5

  # Ensemble of models used for evolution
  models:
    - name: "qwen2.5-coder:7b"
      weight: 0.6
    - name: "mistral:7b"
      weight: 0.4

  # Optional: evaluator_models (if omitted, config.py copies `models` to `evaluator_models`)
  # evaluator_models:
  #   - name: "qwen2.5-coder:7b"
  #     weight: 1.0

# ------------ Prompt configuration ------------
prompt:
  system_message: |
    You are a theoretical physicist and numerical cosmologist specializing in:
      - General Relativity (Einstein field equations)
      - Quantum field theory in curved spacetime
      - Massive gravity and constraints on the graviton mass
      - Cosmological background dynamics (Friedmann equations, ΛCDM)

    You are helping evolve an effective quantum correction ρ_q(a, H, m_g)
    that modifies the Friedmann equation in a controlled, physically-motivated way.

    IMPORTANT (STRICT RULES):
      - Your output MUST contain exactly the code between the EVOLVE markers and nothing else.
        Use these markers exactly and keep them on their own lines:
          # EVOLVE-BLOCK-START
          # EVOLVE-BLOCK-END
      - Only change the code between those markers. Do NOT add, remove or move the marker lines.
      - The evolved code MUST define the following function signature exactly (including name and parameters):
          def rho_quantum(a, H_classical, m_g):
        The rest of the scaffold must remain unchanged.
      - Do NOT include any triple-quoted strings (""" or '''), code fences, or long-form prose in your output.
        Return only valid Python code for the evolve block. Triple-quoted text or unclosed quotes will be rejected.
      - Final reminder: emitting even a single triple-quoted string immediately disqualifies the candidate and wastes the iteration, so keep output strictly to plain Python statements.
      - Do not insert `from __future__` imports or any top-level imports inside the EVOLVE block; place imports only outside the markers.
      - If you deviate from these rules, your output will be rejected and the candidate will be discarded.
    EXPLORATION GUIDELINES:
      - Prioritize bold, physically-motivated restructurings of rho_quantum over tiny coefficient tweaks.
      - It is acceptable to trade a small temporary loss in H0 alignment if you are probing qualitatively new dependencies on a, H_classical, or m_g.
      - Use mixtures of power laws, exponentials, and smooth transitions to explore new early/late-time behaviour; ensure the density stays finite and sign-controlled.
      - Avoid trivial rescalings of the baseline profile—each proposal should introduce a genuine conceptual change.
  evaluator_system_message: "evaluator_system_message"
  num_top_programs: 1
  num_diverse_programs: 6
  use_template_stochasticity: true

# ------------ Database / evolution settings ------------
database:
  in_memory: true
  population_size: 60         # MAP-Elites population
  archive_size: 25
  num_islands: 4
  elite_selection_ratio: 0.2
  exploration_ratio: 0.55
  exploitation_ratio: 0.25
  feature_dimensions: ["complexity", "diversity"]
  feature_bins: 15
  migration_interval: 25
  migration_rate: 0.1
  log_prompts: true

# ------------ Evaluator configuration ------------
evaluator:
  timeout: 60
  max_retries: 3
  cascade_evaluation: true
  cascade_thresholds: [0.5, 0.75]   # we only use stage1 & stage2
  parallel_evaluations: 4
  distributed: false
  use_llm_feedback: false           # keep this OFF for now
  llm_feedback_weight: 0.1
  enable_artifacts: true
  max_artifact_storage: 104857600   # 100MB

# ------------ Evolution trace (optional) ------------
evolution_trace:
  enabled: false
  format: "jsonl"
  include_code: false
  include_prompts: true
  output_path: null
  buffer_size: 10
  compress: false
